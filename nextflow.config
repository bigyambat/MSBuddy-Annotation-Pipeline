/*
========================================================================================
    GNPS Reference Library Annotation Pipeline Configuration
========================================================================================
*/

// Global default parameters
params {
    // Input/Output options
    input                   = null
    outdir                  = 'results'

    // Peak matching parameters
    mz_tol                  = 0.01              // m/z tolerance in Daltons for peak matching
    ppm_tol                 = 20.0              // PPM tolerance for peak matching
    min_peaks               = 3                 // Minimum peaks in spectrum

    // Cosine similarity parameters
    cosine_top_n            = 10                // Number of top similar neighbors to report
    min_similarity          = 0.5               // Minimum cosine similarity to report
    intensity_power         = 0.5               // Power scaling for intensity normalization

    // Annotation quality thresholds
    quality_threshold_good      = 0.7           // Minimum quality score for "good" classification
    quality_threshold_uncertain = 0.4           // Minimum quality score for "uncertain" classification
    min_explained_peaks         = 3             // Minimum number of explained peaks
    min_explained_intensity     = 0.5           // Minimum explained intensity fraction (0-1)

    // Resource limits
    max_memory              = '16.GB'
    max_cpus                = 8
    max_time                = '24.h'

    // Help and version
    help                    = false
    version                 = false
}

// Manifest
manifest {
    name                    = 'gnps-annotation-pipeline'
    author                  = 'Bigy Ambat'
    homePage                = 'https://github.com/yourusername/gnps-annotation-pipeline'
    description             = 'GNPS Reference Library Annotation & Quality Assessment Pipeline'
    mainScript              = 'main.nf'
    nextflowVersion         = '>=21.10.0'
    version                 = '3.0'
}

// Process configuration
process {
    // Default resources for all processes
    cpus   = { check_max( 4, 'cpus' ) }
    memory = { check_max( 8.GB * task.attempt, 'memory' ) }
    time   = { check_max( 16.h * task.attempt, 'time' ) }

    // Error handling
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 2
    maxErrors     = '-1'

    // Process-specific resources
    withName: PARSE_GNPS_REFERENCE {
        cpus   = { check_max( 4, 'cpus' ) }
        memory = { check_max( 8.GB * task.attempt, 'memory' ) }
        time   = { check_max( 16.h * task.attempt, 'time' ) }
    }

    withName: ANNOTATE_PEAKS_GNPS {
        cpus   = { check_max( 4, 'cpus' ) }
        memory = { check_max( 8.GB * task.attempt, 'memory' ) }
        time   = { check_max( 16.h * task.attempt, 'time' ) }
    }

    withName: CALCULATE_COSINE_SIMILARITY {
        cpus   = { check_max( 4, 'cpus' ) }
        memory = { check_max( 16.GB * task.attempt, 'memory' ) }
        time   = { check_max( 8.h * task.attempt, 'time' ) }
    }

    withName: GENERATE_QC_GNPS {
        cpus   = { check_max( 4, 'cpus' ) }
        memory = { check_max( 8.GB * task.attempt, 'memory' ) }
        time   = { check_max( 16.h * task.attempt, 'time' ) }
    }
}

// Execution profiles
profiles {
    // Standard profile (local execution)
    standard {
        process.executor = 'local'
    }

    // Docker profile
    docker {
        docker.enabled         = true
        docker.runOptions      = '-u $(id -u):$(id -g)'
        process.container      = 'gnps-annotation:latest'
    }

    // Singularity profile
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        process.container      = 'gnps-annotation.sif'
    }

    // Conda profile
    conda {
        conda.enabled          = true
        process.conda          = "${baseDir}/environment.yml"
    }

    // HPC cluster profile (SLURM example)
    slurm {
        process.executor       = 'slurm'
        process.queue          = 'batch'
        process.clusterOptions = '--account=your_account'

        // Increase resources for cluster
        process.cpus           = { check_max( 8, 'cpus' ) }
        process.memory         = { check_max( 16.GB * task.attempt, 'memory' ) }
        process.time           = { check_max( 16.h * task.attempt, 'time' ) }
    }

    // PBS/Torque profile
    pbs {
        process.executor       = 'pbs'
        process.queue          = 'batch'
    }

    // SGE profile
    sge {
        process.executor       = 'sge'
        process.queue          = 'all.q'
        process.penv           = 'smp'
    }

    // LSF profile
    lsf {
        process.executor       = 'lsf'
        process.queue          = 'normal'
    }

    // AWS Batch profile
    awsbatch {
        process.executor       = 'awsbatch'
        process.queue          = 'your-aws-batch-queue'
        aws.region             = 'us-east-1'
        aws.batch.cliPath      = '/home/ec2-user/miniconda/bin/aws'
    }

    // Google Cloud profile
    gcp {
        process.executor       = 'google-lifesciences'
        google.region          = 'us-central1'
        google.project         = 'your-project-id'
    }

    // Test profile (for small test datasets)
    test {
        params.max_memory      = '16.GB'
        params.max_cpus        = 8
        params.max_time        = '16.h'
        params.timeout_secs    = 60
    }

    // Debug profile
    debug {
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup                = false
    }
}

// Export environment variables
env {
    PYTHONUNBUFFERED = 1
}

// Timeline, report and trace
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline.html"
}

report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report.html"
}

trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace.txt"
}

dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag.svg"
}

// Function to ensure that resource requirements don't go beyond maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
